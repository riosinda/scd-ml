{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515f0dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(override=True)\n",
    "REPO_DIR = os.getenv(\"DINOV3_DIR\")\n",
    "DINOV3_WEIGHTS = os.getenv(\"DINOV3_WEIGHTS\")\n",
    "DINOV3_BACKBONE = os.getenv(\"DINOV3_BACKBONE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c45b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(REPO_DIR)\n",
    "print(DINOV3_WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73af8cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.transforms import v2\n",
    "from matplotlib import colormaps\n",
    "from functools import partial\n",
    "from dinov3.eval.segmentation.inference import make_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e69d99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA device count:\", torch.cuda.device_count())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU device name:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a149d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img():\n",
    "    import requests\n",
    "    url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "    image = Image.open(requests.get(url, stream=True).raw).convert(\"RGB\")\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa714cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_transform(resize_size: int | list[int] = 768):\n",
    "    to_tensor = v2.ToImage()\n",
    "    resize = v2.Resize((resize_size, resize_size), antialias=True)\n",
    "    to_float = v2.ToDtype(torch.float32, scale=True)\n",
    "    normalize = v2.Normalize(\n",
    "        mean=(0.485, 0.456, 0.406),\n",
    "        std=(0.229, 0.224, 0.225),\n",
    "    )\n",
    "    return v2.Compose([to_tensor, resize, to_float, normalize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebdb8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentor = torch.hub.load(REPO_DIR, 'dinov3_vit7b16_ms', source=\"local\", weights=DINOV3_WEIGHTS,backbone_weights=DINOV3_BACKBONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af10c462",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 896\n",
    "img  = get_img()\n",
    "transform = make_transform(img_size)\n",
    "with torch.inference_mode():\n",
    "    with torch.autocast('cuda', dtype=torch.bfloat16):\n",
    "        batch_img = transform(img)[None]\n",
    "        pred_vit7b = segmentor(batch_img)  # raw predictions  \n",
    "        # actual segmentation map\n",
    "        segmentation_map_vit7b = make_inference(\n",
    "            batch_img,\n",
    "            segmentor,\n",
    "            inference_mode=\"slide\",\n",
    "            decoder_head_type=\"m2f\",\n",
    "            rescale_to=(img.size[-1], img.size[-2]),\n",
    "            n_output_channels=150,\n",
    "            crop_size=(img_size, img_size),\n",
    "            stride=(img_size, img_size),\n",
    "            output_activation=partial(torch.nn.functional.softmax, dim=1),\n",
    "        ).argmax(dim=1, keepdim=True)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(121)\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(122)\n",
    "plt.imshow(segmentation_map_vit7b[0,0].cpu(), cmap=colormaps[\"Spectral\"])\n",
    "plt.axis(\"off\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
