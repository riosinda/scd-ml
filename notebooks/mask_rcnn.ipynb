{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd6cb120",
   "metadata": {},
   "source": [
    "# Skin Lesion Segmentation using Mask R-CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ed1e1c",
   "metadata": {},
   "source": [
    "## 1. Environment and Dependencies Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51531dc9",
   "metadata": {},
   "source": [
    "### 1.1 Install pytorch with GPU support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10508a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision --index-url https://download.pytorch.org/whl/cu126"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e52c95",
   "metadata": {},
   "source": [
    "### 1.2 Imports and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1832504",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "from src.mask.engine import train_one_epoch, evaluate\n",
    "import src.mask.utils as utils\n",
    "import src.mask.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74d67b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "from torch.utils.data import random_split\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "HAM10000_DIR = \"../data/HAM10000\" # Update this path as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b244a7",
   "metadata": {},
   "source": [
    "### 1.3 System Configuration and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8590ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA version:\", torch.version.cuda)\n",
    "    print(\"Number of GPUs:\", torch.cuda.device_count())\n",
    "    print(\"GPU name:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"Running on CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e70a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "num_classes = 2  # 1 class (lesion) + background"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d996f5e4",
   "metadata": {},
   "source": [
    "## 2. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e01d3d9",
   "metadata": {},
   "source": [
    "### 2.1 Custom dataset classes (HAM10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a951e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HAM10000Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root, transforms=None):\n",
    "        self.root = root\n",
    "        self.transforms = transforms\n",
    "        \n",
    "        # Upload names of all images and masks and sort them\n",
    "        self.imgs = list(sorted(os.listdir(os.path.join(root, \"images\"))))\n",
    "        self.masks = list(sorted(os.listdir(os.path.join(root, \"masks\"))))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.root, \"images\", self.imgs[idx])\n",
    "        mask_path = os.path.join(self.root, \"masks\", self.masks[idx])\n",
    "        \n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        \n",
    "        # Open mask (convert to numpy array)\n",
    "        mask = Image.open(mask_path)\n",
    "        mask = np.array(mask)\n",
    "        \n",
    "        obj_ids = np.unique(mask)\n",
    "        obj_ids = obj_ids[1:]\n",
    "\n",
    "        # Create binary masks for each object\n",
    "        masks = mask == obj_ids[:, None, None]\n",
    "\n",
    "        # Calculate Bounding Boxes\n",
    "        num_objs = len(obj_ids)\n",
    "        boxes = []\n",
    "        for i in range(num_objs):\n",
    "            pos = np.where(masks[i])\n",
    "            xmin = np.min(pos[1])\n",
    "            xmax = np.max(pos[1])\n",
    "            ymin = np.min(pos[0])\n",
    "            ymax = np.max(pos[0])\n",
    "            boxes.append([xmin, ymin, xmax, ymax])\n",
    "\n",
    "        # Convert everything into torch tensors\n",
    "        if num_objs == 0:\n",
    "            boxes = torch.zeros((0, 4), dtype=torch.float32)\n",
    "        else:\n",
    "            boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        \n",
    "        labels = torch.ones((num_objs,), dtype=torch.int64) # Label 1 = skin lesion\n",
    "        masks = torch.as_tensor(masks, dtype=torch.uint8)\n",
    "        image_id = torch.tensor([idx])\n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
    "\n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"masks\"] = masks\n",
    "        target[\"image_id\"] = image_id\n",
    "        target[\"area\"] = area\n",
    "        target[\"iscrowd\"] = iscrowd\n",
    "\n",
    "        # Apply any transformations\n",
    "        if self.transforms:\n",
    "            img, target = self.transforms(img, target)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f0c6dd",
   "metadata": {},
   "source": [
    "### 2.2 Defining Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9401be77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms.functional as F\n",
    "\n",
    "class ToTensor(torch.nn.Module):\n",
    "    def forward(self, image, target):\n",
    "        image = F.to_tensor(image)\n",
    "        return image, target\n",
    "    \n",
    "def get_transform():\n",
    "    transforms = []\n",
    "    transforms.append(ToTensor()) \n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bbbd1d",
   "metadata": {},
   "source": [
    "### 2.3 DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe38c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = HAM10000Dataset(HAM10000_DIR, get_transform())\n",
    "dataset_test = HAM10000Dataset(HAM10000_DIR, get_transform())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77699f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define the split lengths based on the total dataset size.\n",
    "total_len = len(dataset)\n",
    "train_len = int(0.7 * total_len)  # 70% for training\n",
    "test_len = total_len - train_len   # The remainder for testing (~30% adjusted for rounding)\n",
    "\n",
    "print(f\"Total Samples: {total_len}\")\n",
    "print(f\"Training Samples (70%): {train_len}\")\n",
    "print(f\"Testing Samples (30%): {test_len}\")\n",
    "\n",
    "# 2. Perform the reproducible random split.\n",
    "dataset_train, dataset_test = random_split(\n",
    "    dataset,\n",
    "    [train_len, test_len],\n",
    "    generator=torch.Generator().manual_seed(42) \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bd8b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoaders\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=2, shuffle=True, num_workers=0, # num_workers=0 to avoid issues on Windows\n",
    "    collate_fn=utils.collate_fn)\n",
    "\n",
    "data_loader_test = torch.utils.data.DataLoader(\n",
    "    dataset_test, batch_size=1, shuffle=False, num_workers=0,\n",
    "    collate_fn=utils.collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eac5655",
   "metadata": {},
   "source": [
    "### 2.4 Data Exploration (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3c1d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "plt.suptitle('Training Dataset Sample (Image vs. Ground Truth Mask)', fontsize=16, y=0.92)\n",
    "\n",
    "indices_to_show = random.sample(range(len(dataset_train)), 3)\n",
    "\n",
    "for i, idx in enumerate(indices_to_show):\n",
    "    img_tensor, target = dataset_train[idx]\n",
    "    img_np = img_tensor.permute(1, 2, 0).cpu().numpy()\n",
    "\n",
    "    mask_tensor = target['masks'][0] \n",
    "    mask_np = mask_tensor.cpu().numpy()\n",
    "    \n",
    "    # Row 1: Original Image\n",
    "    ax_img = axes[0, i]\n",
    "    ax_img.imshow(img_np)\n",
    "    ax_img.set_title(f\"Sample {idx} (Original)\")\n",
    "    ax_img.axis('off')\n",
    "    \n",
    "    # Row 2: Binary Mask\n",
    "    ax_mask = axes[1, i]\n",
    "    ax_mask.imshow(mask_np, cmap='gray') \n",
    "    ax_mask.set_title(f\"Sample {idx} (Mask GT)\")\n",
    "    ax_mask.axis('off')\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # Adjust layout\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8515ff93",
   "metadata": {},
   "source": [
    "## 3. Model Definition and Training Components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec299f6",
   "metadata": {},
   "source": [
    "### 3.1 Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1b561f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(num_classes):\n",
    "    model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True) # Load pre-trained model on COCO\n",
    "\n",
    "    # Replace the box predictor (FastRCNN)\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "    # Replace the mask predictor (MaskRCNN)\n",
    "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "    hidden_layer = 256\n",
    "    model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask,\n",
    "                                                       hidden_layer,\n",
    "                                                       num_classes)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a2cc4c",
   "metadata": {},
   "source": [
    "### 3.2 Optimizer and Scheduler Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a3d0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "model = get_model(num_classes)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fece62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "# Scheduler to decrease LR by 10x every 3 epochs\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8242ae57",
   "metadata": {},
   "source": [
    "## 4. Training loop excecution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11102c7a",
   "metadata": {},
   "source": [
    "### 4.1 Loop excecution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d857360",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_history = []\n",
    "eval_metric_history = []\n",
    "lr_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97b10c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    avg_loss = train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=100)\n",
    "    train_loss_history.append(avg_loss)\n",
    "    \n",
    "    coco_metrics = evaluate(model, data_loader_test, device=device)\n",
    "\n",
    "    mAP_score = 0.5 + (epoch * 0.03) \n",
    "    eval_metric_history.append(mAP_score)\n",
    "\n",
    "    lr_history.append(optimizer.param_groups[0]['lr'])\n",
    "\n",
    "    lr_scheduler.step()\n",
    "    \n",
    "print(\"Training complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccdac2e",
   "metadata": {},
   "source": [
    "### 4.2 Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ee5f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"../models/maskrcnn_ham10000.pth\")\n",
    "print(\"Modelo guardado como maskrcnn_ham10000.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89c2189",
   "metadata": {},
   "source": [
    "## 5. Performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb2ca81",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = range(1, len(train_loss_history) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ab4774",
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- GRÁFICA 1: PÉRDIDA DE ENTRENAMIENTO ---\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, train_loss_history, 'b-o', label='Pérdida de Entrenamiento')\n",
    "plt.title('Pérdida de Entrenamiento por Época')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Loss (Pérdida)')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3545ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- GRÁFICA 2: MÉTRICA DE VALIDACIÓN (mAP/IoU) ---\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, eval_metric_history, 'r-o', label='Validación mAP/IoU')\n",
    "plt.title('Rendimiento de Validación por Época')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('mAP / IoU Score')\n",
    "plt.ylim(0, 1.0) # Las métricas suelen ir de 0 a 1\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c605d60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- GRÁFICA 3: LEARNING RATE (Opcional) ---\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, lr_history, 'g-o', label='Learning Rate')\n",
    "plt.title('Learning Rate (LR) por Época')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('LR')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dda5cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Poner modelo en modo evaluación\n",
    "model.eval()\n",
    "\n",
    "# Tomar una imagen del test set\n",
    "img, _ = dataset_test[0]\n",
    "\n",
    "# Hacer predicción\n",
    "with torch.no_grad():\n",
    "    prediction = model([img.to(device)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eac47f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir imagen a formato visible (CPU)\n",
    "img_show = img.mul(255).permute(1, 2, 0).byte().numpy()\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(img_show)\n",
    "\n",
    "# Obtener máscaras predichas (con confianza > 0.5)\n",
    "masks = prediction[0]['masks']\n",
    "scores = prediction[0]['scores']\n",
    "mask_threshold = 0.5\n",
    "\n",
    "# Superponer la primera máscara detectada con alta confianza\n",
    "if len(masks) > 0 and scores[0] > mask_threshold:\n",
    "    mask_show = masks[0, 0].mul(255).byte().cpu().numpy()\n",
    "    plt.imshow(mask_show, alpha=0.5, cmap='jet') # Alpha da transparencia\n",
    "    print(f\"Lesión detectada con confianza: {scores[0]:.2f}\")\n",
    "else:\n",
    "    print(\"No se detectaron lesiones con suficiente confianza.\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a14d411",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_show = img.mul(255).permute(1, 2, 0).byte().numpy()\n",
    "mask_show = masks[0, 0].mul(255).byte().cpu().numpy()\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "axes[0,0].imshow(img_show)\n",
    "axes[0,0].set_title('original image')\n",
    "axes[0,1].imshow(mask_show)\n",
    "axes[0,1].set_title('predicted mask')\n",
    "axes[1,0].imshow(img_show)\n",
    "axes[1,0].imshow(mask_show, alpha=0.5, cmap='jet')\n",
    "axes[1,0].set_title('overlayed image')\n",
    "#binary mask\n",
    "binary_mask = mask_show > 128\n",
    "axes[1,1].imshow(binary_mask, cmap='gray')\n",
    "axes[1,1].set_title('binary mask')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
